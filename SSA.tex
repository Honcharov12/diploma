\section{Аналіз алгоритму SSA}
%\section{АНАЛІЗ АЛГОРИТМУ SSA}
\label{sec:SSA}

Алгоритм SSA (від англійського Singular Spectrum Analysis) $-$ метод аналізу і прогнозу часових рядів. 

Результатом застосування методу є розкладання тимчасового ряду на прості компоненти: повільні тренди, сезонні та інші періодичні або коливальні складові, а також шумові компоненти. Отримане розкладання може служити основою прогнозування як самого ряду, так і його окремих складових. SSA допускає природне узагальнення на багатовимірні тимчасові ряди, а також на випадок аналізу зображень[13].

Але, перш ніж перейти до самого алгоритму, необхідно розглянути сингулярний розклад $SVD$ (від англійського Singular Value Decomposition).

\subsection{Сингулярний розклад SVD}

Сингулярний розклад (Singular Values Decomposition, SVD) є зручним методом при роботі з матрицями. Cингулярний розклад показує геометричну структуру матриці і дозволяє наочно представити наявні дані. 

SVD використовується при вирішенні найрізноманітніших завдань - від наближення методом найменших квадратів і рішення систем рівнянь до стиснення і розпізнавання зображень. Використовуються різні властивості сингулярного розкладання, наприклад, здатність показувати ранг матриці і наближати матриці даного рангу. Так як обчислення рангу матриці - завдання, яке зустрічається дуже часто, то сингулярне розкладання є досить популярним методом[14].

\subsubsection{Існування і единість}

Нехай $X$ $-$ ненульова матриця з $L > 1$ рядками та $K > 1$ cтовпцями.

Тоді $S = XX^{T}$ $-$ симетрична матриця $L \times L$. $S$ має $L$ лінійно-незалежних власних векторів, або існують такі лінійно-незалежні вектори $U_{1}, \dots, U_{L}$, що:

\[
SU_{i} = \lambda_{i}U_{i}
\]

\noindent де $\lambda_{i}$ $-$ дійсні числа, які називають власними числами матриці $S$. 

Лінійна оболонка власних векторів $U_{i}$ називається власним підпростіром[15].

Ми можемо обрати власні вектори $U_{i}$ отронормованими, тобто:

\begin{enumerate}
	\item $(U_{i}, U_{j}) = 0$, якщо $i \ne j$ (властивість ортогональності);
	\item $||U_{i}|| = 1$ (нормалізація),
\end{enumerate}

\noindent де $(X, Y)$ $-$ скалярний добуток двох векторів, а $||X|| = \sqrt{(X,X)}$ $-$ норма вектору $X$.

Більш того, матриця $S$ є невід'ємно визначеною, тобто усі $\lambda_{i} \ge 0$.

Також, припустимо, що всі власні числа $\lambda_{i}$ спадають, тобто: 

\[
\lambda_{1} \ge \lambda_{2} \ge \dots \ge \lambda_{L} \ge 0.
\]

Нехай $d$ $-$ кількість ненульових власних чисел матриці $S$. Якщо $d < L, \, \lambda_{d} > 0 \, \text{та} \, \lambda_{d+1} = 0$, то всі інші власні числа з номерами, білшими від $d$, є нульовими. Якщо $\lambda_{L} > 0$, то $d = L$[15]. 

Оскільки значення $d$ дорівнює рангу матриці $X$, маємо: $d \le min(L, K)$.

Нехай для всіх $i$ таких, що $1 \le i \le d$ виконується формула \ref{eq:vi}

\begin{equation}\label{eq:vi}
V_{i} = \frac{1}{\sqrt{\lambda_{i}}}X^{T}U_{i}.
\end{equation}

Припустимо, що вектори $U_{i}$ та $V_{i}$ мають наступні властивості:

\begin{enumerate}
	\item Нехай $1 \le i, j \le d$. Тоді $(V_{i}, V_{j}) = 0$ для всіх $i \ne j$ та $||V_{i}|| = 1$. Якщо $i > d$, тоді $X^{T}U_{i}=0_{K} \in \mathds{R}^{K}$, де $0_{K}$ $-$ нульовий вектор;
	\item $V_{i}$ є власним вектором матриці $X^{T}X$, відповідно власному числу $\lambda_{i}$;
	\item якщо $1 \le i \le d$, тоді $U_{i} = \sum^d_{i=1}\sqrt{\lambda_{i}}U_{i}V_{i}^{T}$;
	\item якщо $K > d$, тоді всі решта $K - d$ власних вектора матриці $X^{T}X$ відповідають нульовим власним числам;
	\item справедлива справедлива формула \ref{eq:SVD}:
	\begin{equation}\label{eq:SVD}
	X = \sum_{i=1}^{d}\sqrt{\lambda_{i}}U_{i}V_{i}^{T}.
	\end{equation}
\end{enumerate}

Рівність (\ref{eq:SVD}) називають сингулярним розкладом (SVD) матриці $X$. Числа $\lambda_{i}$ $-$ сингулярними числами матриці $X$, а вектори $U_{i}$ та $V_{i}$ називають лівим та правим сингулярними векторами матриці $X$. Набір $(\sqrt{\lambda_{i}}, \, U_{i}, \, V_{i})$ називають $i$-ою власною трійкою матриці $X$[15].

Єдиність сингулярного розкладу не може сприйматися буквально. Її можна сформулювати використавши наступні твердження.

Нехай $P_{1}, \dots, P_{L}$ та $Q_{1}, \dots, Q_{L}$ $-$ деякі ортонормовані системи у $\mathds{R}^{L}$ та $\mathds{R}^{K}$ відповідно. Припустимо, що існують такі константи $c_{1} \ge \dots \ge c_{L} \ge 0$, що виконується формула \ref{eq:SVD2}.

\begin{equation}\label{eq:SVD2}
X = \sum_{i=1}^{L}c_{i}P_{i}Q_{i}^{T}.
\end{equation}

Розглянемо сингулярний розклад (\ref{eq:SVD}) матриці $X$. Тоді:

\begin{enumerate}
	\item $c_{d} > 0$ та $c_{d+1} = \dots = c_{L} = 0$;
	\item $c_{i}^{2} = \lambda_{i}$ для $1 \le i \le d$;
	\item Для кожного $i = 1, \dots, d$ вектор $P_{i}$ є власним вектором матриці $XX^{T}$, відповідним власному числу $\lambda_{i}$;
	\item $Q_{i} = X^{T}P_{i}/\sqrt{\lambda_{i}}, \, (i=1, \dots, d)$;
	\item У випадку коли всі числа $c_{i}$ різні, то (\ref{eq:SVD2}) співпадає з (\ref{eq:SVD}) з точністю до знаків $U_{i}$ та $V_{i}$.
\end{enumerate}

Нехай $I \subset \{1, \dots, d\}, \, J=\{1, \dots, d\} \textbackslash I$, $X_{I} = \sum_{i \in I}\sqrt{\lambda_{i}}U_{i}V_{i}$ та $X_{J} = X - X_{I}$. Тоді розклад $X_{J} = \sum_{i \in J}\sqrt{\lambda_{i}}U_{i}V_{i}$ є сингулярним розкладом матриці $X_{J}$.

\subsubsection{Матрична форма сингулярного розкладу}

Сингулярний розклад (\ref{eq:SVD}) можна переписати в матричній формі наступним чином.

Нехай $U_{d} = \left[ U_{1} : \dots : U_{d} \right]$, $V_{d} = \left[ V_{1} : \dots : V_{d}\right]$ та $\Lambda_{d}$ $-$ диагональна $d \times d$ матриця з власними числами $\lambda_{i}$ в якості $i$-х диагональних елементів.

Тоді формулу \ref{eq:SVD} можна записати так, як наведено у формулі \ref{eq:SVDMatrix}.

\begin{equation}\label{eq:SVDMatrix}
X = U_{d}\Lambda_{d}^{1/2}V_{d}^{T}
\end{equation}

\noindent що є стандартною матричною формою сингулярного розкладу.

Рівність (\ref{eq:SVDMatrix}) можна переписати у формі, відомій як квазі-діагональна форма матриці $X$. Як відомо, при відповідному виборі ортонормованого базису у $\mathds{R}^{L}$ будь-яка симетричка $L \times L$ матриця має совє діагональну форму. З (\ref{eq:SVDMatrix}) випливає, що можна обрати відповідні базиси у $\mathds{R}^{L}$ та $\mathds{R}^{K}$ так, шоб отримати аналогічну форму для прямокутної матриці $X$.

Нехай $U = [U_{1}: \dots : U_{L}]$, $V = [V_{1}: \dots : V_{K}]$. Матриці $U_{L \times L}$ та $V_{K \times K}$ $-$ унітарні матриці. Для матриці $U$ це означає, що для будь-яких векторів $X,Y \in \mathds{R}^{L}$ рівність $(UX, UY) = (X, Y)$ є справедливою і, відповідно, матриця $U$, розглядаєма як лінійне відображення $\mathds{R}^{L} \mapsto \mathds{R}^{L}$, зберігає векторні норми та кути між векторами. Іншою характеристикою властивості унітарності є тотожність $U^{-1}=U^{T}$.

Позначимо $\Lambda$ матрицю тієї ж розмірності як і матриця $X$ з діагональними елементами $\lambda_{ii} = \lambda_{i}$ за умови $1 \le i \le d$ та всіми іншими елементами, які дорівнюють нулю. Тоді (\ref{eq:SVDMatrix}) можна переписати у вигляді формули \ref{eq:kvazidiag}.

\begin{equation}\label{eq:kvazidiagX}
X = U\Lambda^{1/2}V^{T} \, \text{або} \, \Lambda{1/2}=U^{T}XV
\end{equation}

Рівність (\ref{eq:kvazidiagX}) $-$ це квазі-діагональна форма матриці $X$. При відповідних базисах $U_{1}, \dots, U_{L}$ у $\mathds{R}^{L}$ та $V_{1}, \dots, V_{K}$ у $\mathds{R}^{K}$, будь-яка прямокутна матриця розмірності $L \times K$ має квазі-діагональну форму $\Lambda^{1/2}$.

\subsubsection{Висновки}

Сингулярний розклад є потужним обчислювальним інструментом. Сучасні алгоритми отримання такої декомпозиції загальних матриць мали глибокий вплив на численні застосування в науково-технічних дисциплінах. SVD зазвичай використовується у вирішенні незміщених лінійних задач найменших квадратів, оцінки матричного рангу та канонічного кореляційного аналізу. В обчислювальній науці вона зазвичай застосовується в таких областях, як пошук інформації, сейсмічна рефлекторна томографія і обробка сигналів у реальному часі [16].

\subsection{Алгоритм SSA}

Нехай $F = (f_{0}, \dots, f_{N-1})$ $-$ часовий ряд що складається з дійсних значень довжини $N$, де $N > 2$. Передбачається що ряд $F$ має хоча б одне нульове значення.

Алгоритм SSA в своїй базовоей версії має чотири формальних кроки: 

\begin{enumerate}
	\item вкладення; 
	\item сингулярний розклад;
	\item угруповання;
	\item діагональне усереднення. 
\end{enumerate}	
Розглянемо кожен з цих кроків.

\subsubsection{Вкладення}

Нехай $L$ - ціле число, таке що $1 < L < N$, яке назвемо довжиною вікна. Процедура вкладення перетворює вихідний часовий ряд в $K = N - L + 1$ векторів вкладення $x_{i}$ за таким правилом:

\[
x_{i} = (f_{i-1}, \dots, f_{i+L-2})^{T}, \, 1 \le i \le K.
\]

Отримані вектори $x_{i}$ мають розмірність $L$, тому якщо в подальшому знадобиться підкреслити їх розмірність будемо називати їх векторами $L$-вкладення.

З векторів $L$-вкладення $x_{i}$ ми отримуємо $L$-траєкторну матрицю $X$ ряду $F$ за таким правилом:

\[
X = [x_{1} : x_{2} : \dots : x_{K-1} : x_{K}].
\]

Тобто матриця $X$ відносто елементів ряду $F$ буде мати вигляд наведений у формулі \ref{eq:traekt}.

\begin{equation}\label{eq:traekt}
X = \left(\begin{array}{ccccc} 
f_{0} & f_{1} & f_{2} & \dots & f_{K-1} \\
f_{1} & f_{2} & f_{3} & \dots & f_{K} \\
f_{2} & f_{3} & f_{4} & \dots & f_{K+1} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
f_{L-1} & f_{L} & f_{L+1} & \dots & f_{N-1} \\
\end{array}\right).
\end{equation}

\subsubsection{Сингулярний розклад}

Нехай $S = XX^{T}$ та $\lambda_{1}, \dots, \lambda_{L}$ $-$ власні числа матриці $S$, такі що $\lambda_{1} \ge \lambda_{2} \ge \dots \ge \lambda_{L} \ge 0$. Нехай $u_{1}, \dots, u_{L}$ $-$ власні вектори матриці $S$ з індексами відповідними власним числам матриці $S$.

Нехай $d = \underset{\lambda_{i} \ge 0}{max}(i)$, тоді $v_{i}$ будемо обчислювати так, як запропоновано у формулі \ref{eq:vissa}.

\begin{equation}\label{eq:vissa}
v_{i} = \frac{X^{T}u_{i}}{\sqrt{\lambda_{i}}}, \, \text{де} \, i=1 \dots d.
\end{equation}

Після цього в такий спосіб може бути отримано сингулярний розклад ($SVD - Singular Value Decomposition$) $L$-траєкторної матриці $X$ ряду $F$. Його наведено у формулі \ref{eq:SVDmain}.

\begin{equation}\label{eq:SVDmain}
X = X_{1} + X_{2} + \dots + X_{d}, \, \text{за умови} \, X_{i} = u_{i} \cdot v_{i}^{T} \cdot \sqrt{\lambda_{i}}.
\end{equation}

Матриці $X_{i}$ будемо називати елементарними матрицями сингулярного розкладу (\ref{eq:SVDmain}), набір $(\sqrt{\lambda_{i}}, u_{i}, v_{i})$ $-$ $i$-ою власної трійкою сингулярного розкладу (\ref{eq:SVDmain}), де $\sqrt{\lambda_{i}}$ $-$ сингулярні числа, а $u_{i}$ та $v_{i}$ $-$ ліві і праві сингулярні вектори.

Варто зазначити що так як рядки і стовпці вихідної траєкторної матриці є відрізками вихідного ряду. Тому лівий і правий сингулярні вектора також мають часову структуру і можуть розглядатися як часові ряди [15].

Не кожен сингулярний поділ коректно розділяє траєкторну матрицю на складові. Коректність результату поділу визначається на етапі угруповання і сильно залежить від довжини вікна.

На жаль, немає жодних правил для вибору правильної довжини вікна. Є тільки ряд безіменних теорем на основі яких складено ряд рекомедацій, який буде освітлений далі:

\begin{enumerate}
	\item не має сенс брати довжину вікна більш ніж половина ряду;
	\item чим більше довжина вікна, тим більш детальним виходить розкладання вихідного ряду;
	\item мінімальна довжина вікна може призвести до змішування інтерпретованих компонент ряду;
	\item результати слабкої роздільності стійкі до малих змін довжини вікна;
	\item для рядів зі складною структурою занадто велика довжина вікна може привести до небажаного розкладання цікавлячих нас компонент;
	\item мале зміна довжини вікна може зменшити змішування.
\end{enumerate}

\subsubsection{Угруповання}

На основі сингулярного розкладу (\ref{eq:SVDmain}) ми отримали множину з $d$ елементарних матриць. Процедура угруповання ділить цю множину на $m$ непересічних підмножин $I_{1}, I_{2}, \dots, I_{m}$ та називається угрупованням власних трійок. Сума елементів кожного з цих підмножин дасть нам набір траєкторних матриць, які відповідають за різні складові тренда, періодика і шуму.

Оскільки не завжди сингулярний розклад дає нам чистий розклад ряду на компоненти процедура угруповання здійсненна не завжди, що обумовлює неавтоматізацію всього методу.

Крім того, як і у випадку з довжиною вікна, немає конкретних правил для виконання угруповання, лише рекомендації, які не завжди застосовні. 

Розглянемо ці рекомендації:

\begin{enumerate}
	\item сингулярне значення описує ступінь вкладу сингулярной трійки в розкладання, чим більше значення, тим більший внесок;
	\item компонента відновлена з однієї власної трійки матиме таку ж форму як і відповідні сингулярні вектори;
	\item факторний вектор більше власного схожий на відновлювану компоненту ряду при $L \ll K$;
	\item якщо $N, L, K$ доволі великі, то кожна відмінна від пилкоподібної гармонійна компонента породжує пару власних трійок з близькими власними числами;
	\item при виділенні пар гармонік з близькими амплітудами відповідні факторні (і власні) вектори власних трійок з близькими значеннями утворюють точки лежать на колі.
\end{enumerate}

\subsubsection{Діагональне усереднення}

Даний етап відновлює з сум згрупованих на попередньому етапі елементарних матриць власне складові ряду.

Так як вихідна матриця $X$ є $L$-траєкторної, то і всі елементарні матриці так само є $L$-траєкторні. Однак на практиці таке майже ніколи не проявляється і зберігається тільки розмірність матриць.

Але інформація в цих матрицях все ще відповідає характеристикам згрупованих складових вихідного ряду. Тому має місце етап діагонального усереднення.

Нехай $Y$ $-$ матриця розмірності $L \times K$ з елементами $y_{i,j}$, де $1 \le i \le L$, $1 \le j \le K$. Нехай $L^{*} = min(L, K), \, K^{*} = max(L,K), \, N = L + K - 1$. Нехай $y_{ij}^{*} = y_{ij}$ якщо $L < K$ та $y_{ij}^{*} = y_{ji}$ в іншому випадку.

Тоді діагональне усереднення, яке переводить матрицю $Y$ розмірності $L \times K$ у ряд $g_{0}, g_{1}, \dots, g_{N-1}$ виражається наступним чином:

\[
g_{k} = \begin{cases}
\frac{1}{k+1}\sum_{m=1}^{k+1}y_{m,k-m+2}^{*}, &\text{коли } 0 \le k < L^{*} - 1; \\
\frac{1}{L^{*}}\sum_{m=1}^{L^{*}}y_{m,k-m+2}^{*}, &\text{коли } L^{*} - 1 \le k < K^{*}; \\
\frac{1}{N-k}\sum_{m=k-K^{*}+1}^{N-K^{*}+1}y_{m,k-m+2}^{*}, &\text{коли } K^{*} \le k < N.
\end{cases}
\]

\subsubsection{Проблема роздільності ряду}

Спочатку передбачається, що ряд $F$ є сумою $m$ рядів. Але отримати ці ряди як результат угруповання елементарних сингулярних матриць не є тривіальним завданням. Щоб її вирішити необхідно провести діагональне усереднення над елементарними матрицями і перевірити отримані ряди на роздільність. Після проведення даного дослід вання можна зробити висновок про те, чи правильно обрана довжина вікна і як групувати елементарні матриці в $m$ компонент ряду $F$.

\subsubsection{Основні визначення}

Нехай $F_{N}^{(1)}$ та $F_{N}^{(2)}$ $-$ часові ряди довжини $N$, та $F_{N} = F_{N}^{(1)} + F_{N}^{(2)}$. Нехай за довжини вікна $L$ кожен з рядів $F_{N}$, $F_{N}^{(1)}$ та $F_{N}^{(2)}$ породжує $L$-траєкторні матриці $X$, $X^{(1)}$ та $X^{(2)}$[15].

Нехай $\Lambda^{(L,1)}$, $\Lambda^{(L,2)}$ $-$ лінійні простори, породжені стовпцями траєкторних матриць $X^{(1)}$ та $X^{(2)}$ відповідно. Аналогічно $\Lambda^{(K,1)}$, $\Lambda^{(K,2)}$ $-$ лінійні простори, породжені стовпцями траєкторних матриць $(X^{(1)})^{T}$ та $(X^{(2)})^{T}$ відповідно.

Ряди $F_{N}^{(1)}$ та $F_{N}^{(2)}$ називають слабко $L$-роздільними, якщо

\[
	\left\{
	\begin{aligned}
	\Lambda^{(L,1)} \bot \Lambda^{(L,2)}
	\Lambda^{(K,1)} \bot \Lambda^{(K,2)}
	\end{aligned}
	\right.
\]

Якщо ряди $F_{N}^{(1)}$ і $F_{N}^{(2)}$ слабко $L$-роздільні і множина власних чисел розкладання траєкторної матриці одного ряду не перетинається з множиною власних чисел сингулярного розкладання іншого ряду, то ряди $F_{N}^{(1)}$ і $F_{N}^{(2)}$ називаються сильно $L$-роздільними.

\subsubsection{Точна роздільність}

Розглядаючи роздільність різних тестових рядів, а зокрема константний ряд, експонента, синус / косинус, косинус-екпонента і поліноміальний ряд, в табл. \ref{tab:exactsep} робиться висновок про принаймні теоретичної слабкою разделимости рядів цих типів:

\begin{table}[h]
	\captionstyle{ \raggedright}
	\caption{Точна роздільність}\label{tab:exactsep}
	\centering
	\begin{tabular}{| p{0.1\textwidth} | p{0.1\textwidth} | p{0.1\textwidth} | p{0.1\textwidth} | p{0.1\textwidth} | p{0.1\textwidth} |}
	\hline
	 & const & cos & exp & exp cos & ak+b \\
	\hline
	const & - & + & - & - & - \\
	\hline
	cos & + & + & - & - & - \\
	\hline
	exp & - & - & - & + & - \\
	\hline
	exp cos & - & - & + & + & - \\
	\hline
	ak + b & - & - & - & - & - \\
	\hline
	\end{tabular}
\end{table}

У таблиці знаком + позначені пари, для яких існують параметри функцій і параметри методу $L$ і $K = N - L + 1$, при яких ряди слабко $L$-роздільні. Табл. \ref{tab:exactsep} показує що умови разделимости є досить жорсткими [15].

\subsubsection{Наближена і асимптотична роздільність}

Через жорсткості рамок умови слабкої і тим більш сильної роздільності майже не застосовні в реальних задачах. Тому вводиться поняття наближеною разделимости, яке використовує ідею ортогональности лінійних просторів породжених стовпцями траєкторних матриць.

Для будь-якого ряду $F_{N} = (f_{0}, f_{1}, \dots, f_{N-1})$ приймемо:

\[
F_{i,j} = (f_{i-1}, \dots, f_{j-1}), \text{ де } 1 \le i \le j < N.
\]

Тоді визначимо коефіцієнт кореляції рядів. Він обчислюється так, як показано у формулі \ref{eq:koefkor}.

\begin{equation}\label{eq:koefkor}
\rho_{i,j}^{(M)} = \frac{(F_{i,i+M-1}^{(1)}, F_{j,j+M-1}^{(2)})}{||F_{i,i+M-1}^{(1)}|| \cdot ||F_{j,j+M-1}^{(2)}||}
\end{equation}

Часові ряди $F_{N}^{(1)}$ та $F_{N}^{(2)}$ називають слабко $\varepsilon$-роздільними, якщо при довжині вікна $L$ та при малому $\varepsilon$ виконується нерівність \ref{eq:epssep}.

\begin{equation}\label{eq:epssep}
\rho^{(L,K)} = max(\underset{1 \le i,j \le K}{max}|\rho_{i,j}^{(L)}|, \underset{1 \le i,j \le L}{max}|\rho_{i,j}^{(K)}|) < \varepsilon
\end{equation}

Обираючи послідовність довжин вікон $1 < K = L(N) < N$ з нерівності (\ref{eq:epssep}) можна отримати послідовність максимальних коефіцієнтів кореляції $\rho_{N} = \rho^{(L(N),K(N))}$.

Якщо $\rho^{(L(N),K(N))} \longrightarrow 0$ при деякій послідовності $L=L(N)$ та $N \longrightarrow \infty$, то ряди $F_{N}^{(1)}$ та $F_{N}^{(2)}$ називають асимптотично $L(N)$-роздільними. Якщо ряди $F_{N}^{(1)}$ та $F_{N}^{(2)}$ асимптотично $L(N)$-роздільні при будь-якому виборі послідовності $L(N)$, такої що $L(N) \longrightarrow \infty$ та $K(N) \longrightarrow \infty$ їх називають асимптотично роздільними.

Аналогічно точної роздільності в табл. \ref{tab:assep} приведений результат дослідження асимптотичної роздільності.

\begin{table}[h]
	\captionstyle{ \raggedright}
	\caption{Асимптотична роздільність}\label{tab:assep}
	\centering
	\begin{tabular}{| p{0.1\textwidth} | p{0.1\textwidth} | p{0.1\textwidth} | p{0.1\textwidth} | p{0.1\textwidth} | p{0.1\textwidth} |}
	\hline
	 & const & cos & exp & exp cos & ak+b \\
	\hline
	const & - & + & + & + & - \\
	\hline
	cos & + & + & + & + & + \\
	\hline
	exp & + & + & + & + & + \\
	\hline
	exp cos & + & + & + & + & + \\
	\hline
	ak + b & - & + & + & + & - \\
	\hline
	\end{tabular}
\end{table}

Табл. \ref{tab:assep} показує що асімтотічна роздільність застосовна для набагато більш широкого набору класів рядів, ніж точна роздільність.

\subsubsection{Сильна роздільність}

До сих пір розглядалися умови тільки слабкою разделимости рядів. Однак, навіть при наявності слабкої роздільності, але відсутності сильної робить практично неможливою поділ цих рядів. Через співпадаючі власні числа варіант сингулярного розкладу, який має місце на практиці не буде розділяти ряди.


\subsection{Висновки}

Ціллю метода є розкладання часового ряду на інтерпретовані адитивні складові. При цьому метод не потребує стаціонарності ряду, знань моделі тренду, а також відомостей о наявності у ряді періодичних складових та іхніх періодах.

За таких слабких припущень метод SSA може вирішувати різноманітні задачі, такі як, наприклад, виділення тренду, виявлення періодик, згладжування ряду, побудова полного розкладу ряду у суму тренду, періодик та шуму.

З іншого боку, платою за такий широкий спектр можливостей при досить слабких припущеннях є, по-перше, істотне неавтоматичне групування компонент сингулярного розкладу траєкторної матриці ряду задля отримання складових вихідного ряду, 

По-друге, відсутність моделі не дає можливості перевірити гіпотези про наявність тієї чи іншої складової. Для перевірки подібних гіпотез необхідна побудова моделі, яка, в свою чергу, може бути проведена базуючись на інформації, яку ми отримали за допомоги методу SSA.

Розглядаємий непараметричний метод дозволяю отримати результати не гірше, ніж більшість параметричних методів, коли аналізується ряд з відомою моделлю.
